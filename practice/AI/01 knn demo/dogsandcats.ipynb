{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Supervised Learning\n",
        "## k-Nearest Neighbour Demo\n",
        "In the unit material we saw a demo of how we could classify dogs and cats based on weight and tail length data. Here it is again:\n",
        "\n",
        "| class | weight | tail length |\n",
        "|:-----:|:------:|:-----------:|\n",
        "|  dog  |   25   |      20     |\n",
        "|  dog  |   65   |      45     |\n",
        "|  dog  |    3   |      5      |\n",
        "|  dog  |   35   |      30     |\n",
        "|  cat  |    5   |      25     |\n",
        "|  cat  |    3   |      20     |\n",
        "|  cat  |    7   |      46     |\n",
        "\n",
        "When we actually implement supervised learning algorithms we need this data in a usable form. Words like 'dog' and 'cat' are not very useful or relevant to the actual algorithm, so we assign each class a *label*, normally an integer. Let's say 'dog' is represented by `1` and cat is represented as `0`.\n",
        "\n",
        "Now our entire table is made of integers. Since it is a table, we store it in the corresponding data structure. A programmer might call it a 2D array. A mathematician or theoretical computer scientist might call it a matrix. numpy calls everything an array!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The shape of the training data is (7, 3)\n",
            "Row 3 is [ 1 35 30]\n",
            "Row 3 has weight 35\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "\n",
        "training_data = np.array([[1, 25, 20], \n",
        "                          [1, 65, 45],\n",
        "                          [1, 3, 5],\n",
        "                          [1, 35, 30],\n",
        "                          [0, 5, 25],\n",
        "                          [0, 3, 20],\n",
        "                          [0, 7, 46]])\n",
        "\n",
        "print(f\"The shape of the training data is {training_data.shape}\")\n",
        "print(f\"Row 3 is {training_data[3]}\")\n",
        "print(f\"Row 3 has weight {training_data[3][1]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Our training data is a $7 \\times 3$ matrix. It contains the *response variables* (the class labels in this case) in the first column. We might also decide to separate these, giving one array of size $7 \\times 1$ of labels and one of size $7 \\times 2$ of data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "trusted": true
      },
      "outputs": [],
      "source": [
        "# the : in an expression means means \"all\"\n",
        "# so m[:, 0] means all rows, column zero \n",
        "# i.e. this gets the first column of matrix m\n",
        "# remember: always \"row by column\"!\n",
        "\n",
        "training_labels = training_data[:, 0]\n",
        "training_inputs = training_data[:, 1:]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Given a new query point, the k-Nearest Neighbour algorithm finds the distance from the query point to every point in the training set. It then selects the k closest points, the class of each point can be considered a single vote, and whatever class gets the most votes is used to classify the point. Normally odd values for k are used to avoid ties. In more advanced versions the votes could be weighted by their distance from the query.\n",
        "\n",
        "There is a very simple implementation of this below. It's been written mostly with for loops and could be made much more efficient and elegant with clever use of numpy inbuilt functions. See if you can follow it, and think about ways you could make it more efficient."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Predict that [40 30] is class 1 (k=1)\n",
            "Predict that [20 20] is class 1 (k=1)\n",
            "Predict that [20 20] is class 0 (k=3)\n"
          ]
        }
      ],
      "source": [
        "def knn_predict(query, training_data, k = 1):\n",
        "    training_labels = training_data[:, 0]\n",
        "    training_inputs = training_data[:, 1:]\n",
        "    \n",
        "    if query.shape[0] != training_inputs.shape[1]:\n",
        "        raise KeyValueError(\"query point does not have correct shape\")\n",
        "    \n",
        "    # find the distance from query to every row in training_inputs\n",
        "    distances = np.zeros(training_inputs.shape[0])\n",
        "    for i, training_point in enumerate(training_inputs):\n",
        "        # find the Euclidean distance\n",
        "        total_sum = 0\n",
        "        for dim in range(0, training_point.shape[0]):\n",
        "            total_sum += (training_point[dim] - query[dim]) ** 2\n",
        "        distances[i] = np.sqrt(total_sum)\n",
        "    \n",
        "    # take the points with the k lowest distances\n",
        "    # np.argsort returns the indices of each element in sorted order\n",
        "    # but we could have used more for loops instead!\n",
        "    sorted_indices = np.argsort(distances)\n",
        "    k_closest_indices = sorted_indices[:k]\n",
        "    k_closest_classes = training_labels[k_closest_indices]\n",
        "    \n",
        "    # now find the most common element\n",
        "    votes_for_1 = np.count_nonzero(k_closest_classes == 1)\n",
        "    \n",
        "    if votes_for_1 > k/2:\n",
        "        return 1\n",
        "    else:\n",
        "        return 0\n",
        "    \n",
        "query = np.array([40, 30])\n",
        "prediction = knn_predict(query, training_data)\n",
        "print(f\"Predict that {query} is class {prediction} (k=1)\")\n",
        "\n",
        "query = np.array([20, 20])\n",
        "prediction = knn_predict(query, training_data)\n",
        "print(f\"Predict that {query} is class {prediction} (k=1)\")\n",
        "\n",
        "query = np.array([20, 20])\n",
        "prediction = knn_predict(query, training_data, k = 3)\n",
        "print(f\"Predict that {query} is class {prediction} (k=3)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Remember that kNN extends nicely into higher dimensions, it is just harder to visualise what it means to take the distance between two points in 5 or 20 dimensions.\n",
        "\n",
        "The next cell loads some data about animals, based on some data from the [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/Zoo). The idea is to try to classify whether the animal is a mammal or not based on various attributes, all Boolean: whether it has feathers, whether it is toothed, whether it has a tail, whether it the same size as a cat, and so on. I've already stripped out the attributes that would completely give the game away, like whether it produces milk!\n",
        "\n",
        "This time we will treat the data properly by separating it into two groups, one to use as the training data for kNN, and the rest to use as test data to see how well it performs. See if you can follow the code below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The attributes are: \n",
            "['animal_name' 'mammal' 'feathers' 'airborne' 'aquatic' 'predator'\n",
            " 'toothed' 'backbone' 'breathes' 'venomous' 'fins' 'tail' 'domestic'\n",
            " 'catsize']\n",
            "Preview of the data:\n",
            "[['dove' '0' '1' ... '1' '1' '0']\n",
            " ['cheetah' '1' '0' ... '1' '0' '1']\n",
            " ['wasp' '0' '0' ... '0' '0' '0']\n",
            " ...\n",
            " ['raccoon' '1' '0' ... '1' '0' '1']\n",
            " ['oryx' '1' '0' ... '1' '0' '1']\n",
            " ['lobster' '0' '0' ... '0' '0' '0']]\n",
            "zoo_all_data has shape (101, 14)\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\ALEXDR~1\\AppData\\Local\\Temp/ipykernel_22476/3272119399.py:3: DeprecationWarning: `np.object` is a deprecated alias for the builtin `object`. To silence this warning, use `object` by itself. Doing this will not modify any behavior and is safe. \n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  zoo_all_data = np.loadtxt('data/zoo.csv', delimiter=',', dtype=np.object)\n"
          ]
        }
      ],
      "source": [
        "np.random.seed(4)\n",
        "\n",
        "zoo_all_data = np.loadtxt('data/zoo.csv', delimiter=',', dtype=np.object)\n",
        "print(f\"The attributes are: \\n{zoo_all_data[0, :]}\")\n",
        "zoo_all_data = zoo_all_data[1:, :]\n",
        "np.random.shuffle(zoo_all_data)\n",
        "print(\"Preview of the data:\")\n",
        "print(zoo_all_data)\n",
        "print(f\"zoo_all_data has shape {zoo_all_data.shape}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {
        "trusted": true
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "+ sealion correctly classified as 1\n",
            "+ mole correctly classified as 1\n",
            "+ catfish correctly classified as 0\n",
            "+ gnat correctly classified as 0\n",
            "+ wren correctly classified as 0\n",
            "+ porpoise correctly classified as 1\n",
            "+ ostrich correctly classified as 0\n",
            "+ starfish correctly classified as 0\n",
            "+ seahorse correctly classified as 0\n",
            "- slowworm incorrectly classified as 1\n",
            "+ duck correctly classified as 0\n",
            "- tortoise incorrectly classified as 1\n",
            "+ aardvark correctly classified as 1\n",
            "+ bear correctly classified as 1\n",
            "- newt incorrectly classified as 1\n",
            "+ herring correctly classified as 0\n",
            "+ leopard correctly classified as 1\n",
            "+ vole correctly classified as 1\n",
            "+ hare correctly classified as 1\n",
            "+ parakeet correctly classified as 0\n",
            "- tuatara incorrectly classified as 1\n",
            "+ worm correctly classified as 0\n",
            "- penguin incorrectly classified as 1\n",
            "+ cavy correctly classified as 1\n",
            "+ mongoose correctly classified as 1\n",
            "+ scorpion correctly classified as 0\n",
            "+ swan correctly classified as 0\n",
            "+ antelope correctly classified as 1\n",
            "+ raccoon correctly classified as 1\n",
            "+ oryx correctly classified as 1\n",
            "+ lobster correctly classified as 0\n",
            "\n",
            "Total accuracy is 0.8387096774193549\n"
          ]
        }
      ],
      "source": [
        "# split data into training and testing, 70 training and 31 testing\n",
        "zoo_training_data = zoo_all_data[:70, :]\n",
        "zoo_testing_data = zoo_all_data[70:, :]\n",
        "\n",
        "# split the names (not used in the actual classification), labels, and other variables\n",
        "zoo_testing_names = zoo_testing_data[:, 0]\n",
        "zoo_testing_labels = zoo_testing_data[:, 1].astype(np.int)\n",
        "zoo_testing_inputs = zoo_testing_data[:, 2:].astype(np.int)\n",
        "\n",
        "# split the names off the training data too (but leave labels)\n",
        "zoo_training = zoo_training_data[:, 1:].astype(np.int)\n",
        "\n",
        "# now go through each of the testing set and see how many kNN predicts correctly\n",
        "score = 0\n",
        "for i in range(0, zoo_testing_inputs.shape[0]):\n",
        "    test_input = zoo_testing_inputs[i, :]\n",
        "    test_correct_label = zoo_testing_labels[i]\n",
        "    test_name = zoo_testing_names[i]\n",
        "    \n",
        "    prediction = knn_predict(test_input, zoo_training, k = 3)\n",
        "    \n",
        "    if prediction == test_correct_label:\n",
        "        print(f\"+ {test_name} correctly classified as {prediction}\")\n",
        "        score += 1\n",
        "    else:\n",
        "        print(f\"- {test_name} incorrectly classified as {prediction}\")\n",
        "        \n",
        "accuracy = score/zoo_testing_data.shape[0]\n",
        "print(f\"\\nTotal accuracy is {accuracy}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "The total accuracy looks to be about 84%, which doesn't seem too bad for such a simple algorithm. On its own that's useful to know, but the real value of testing your algorithm is so that you can compare different approaches, or to help you pick the parameters. Here we used `k=3`, but maybe we would get better results using 1-nearest neighbour or 5-nearest neighbour?\n",
        "\n",
        "As it happens, this dataset gets the same accuracy for all reasonable values of k, but for a larger problem, this is where you could try the various settings before picking which one is best. Then, once you are done, you can use all of the data to form the final model – in this case that would simply mean using all of the data during the kNN algorithm.\n",
        "\n",
        "You might also want to make better use of all of the data, perhaps the 30% we picked here just happen to be particularly difficult examples? We can get a better estimate of how the entire dataset will perform if we perform multiple rounds of *k-fold cross validation*. Refer to the unit material to learn more."
      ]
    }
  ],
  "metadata": {
    "interpreter": {
      "hash": "cb21fdbaa771a4fddf84119453888cf1c6c7a3c7a9530ce0e9ba55a37ac0d4bb"
    },
    "kernelspec": {
      "display_name": "Python 3.9.0 64-bit",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
